{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tWhat is a classification problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification problem we have deal with qualitative data or categorical data.\n",
    "# in this problem  first predict the probability of each of the categories of the qualitaive varibale\n",
    "# we have  categories the in the prediction outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tWhat is Logistic Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression is regression algorithm which can be used for classification problem\n",
    "# it calculates the probability that a given data belongs to a specific problem.\n",
    "# if the probability is less then 50% it asign the value in this class else the probability is more\n",
    "# than 50% , the other value is assign to this class.\n",
    "# it act like a binary classifier\n",
    "# For linear regression, the model is defined by:  ğ‘¦=ğ›½0+ğ›½1ğ‘¥  - (i)\n",
    "\n",
    "#and for logistic regression, we calculate probability, i.e. y is the probability of a given variable x belonging to a certain class. Thus, it is obvious that the value of y should lie between 0 and 1.\n",
    "\n",
    "#But, when we use equation(i) to calculate probability, we would get values less than 0 as well as greater than 1. That doesnâ€™t make any sense . So, we need to use such an equation which always gives values between 0 and 1, as we desire while calculating the probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tWhy is the Sigmoid function used for Logistic Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sigmod function range is bounded between 0 to 1.\n",
    "# thus it is useful in calculating the probability for the Logistic function\n",
    "# its derivative is easy to calculate than other function ,which is useful in gradient descent calculation\n",
    "# its simply way to introducing non-linearity to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tWhat is the cost function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost funcion is give estimate hiw badly models are performing.\n",
    "# how bad our model is innterm of ability to estimate the relationship between x and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.\tWhat is multiple Logistic Function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In multiple logistic function their are one categorical derived feature which predicted by more than one independent variable.\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.\tWhat is multilabel Logistic Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification problems where the number of classes is greater than 2.\n",
    "# We can extend Logistic regression for multi-label logistic classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\tHow does the Logistic Regression Algorithm learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this algorithm learns i gradient descent apraoch\n",
    "# we us batch gradient descent which calculate the gradient of each point in the data set.\n",
    "#  Our weight update rule per batch gradient descent becomes\n",
    "\n",
    "# ğ°ğ‘–+1=ğ°ğ‘–âˆ’ğœ‚âˆ‡ğ¸in(ğ°ğ‘–)=ğ°ğ‘–âˆ’ğœ‚(âˆ’1ğ‘âˆ‘ğ‘›=1ğ‘ğ‘¦ğ‘›ğ±ğ‘›1+ğ‘’ğ‘¦ğ‘›ğ°ğ‘‡ğ‘–ğ±ğ‘›)=ğ°ğ‘–+ğœ‚(1ğ‘âˆ‘ğ‘›=1ğ‘ğ‘¦ğ‘›ğ±ğ‘›1+ğ‘’ğ‘¦ğ‘›ğ°ğ‘‡ğ‘–ğ±ğ‘›)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.\tExplain the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by using confusion matrix we can estimate the performance of the model.\n",
    "# it is generaly 2* 2 matrix or n*n matrix based on requirements of model\n",
    "\n",
    "#Where the terms have the meaning:\n",
    "\n",
    "#ï± True Positive(TP): A result that was predicted as positive by the classification model and also is positive\n",
    "\n",
    "#ï± True Negative(TN): A result that was predicted as negative by the classification model and also is negative\n",
    "\n",
    "#ï± False Positive(FP): A result that was predicted as positive by the classification model but actually is negative\n",
    "\n",
    "#ï± False Negative(FN): A result that was predicted as negative by the classification model but actually is positive.\n",
    "\n",
    "#The Credibility of the model is based on how many correct predictions did the model do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.\tWhat is Accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it defines how much accurate our model is.\n",
    "#The mathematical formula is : Accuracy=  (ğ‘‡ğ‘ƒ+ğ‘‡ğ‘)(ğ‘‡ğ‘ƒ+ğ‘‡ğ‘+ğ¹ğ‘ƒ+ğ¹ğ‘) \n",
    "#  it can be said that itâ€™s defined as the total number of correct classifications divided by the total number of classifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.\tWhy there is a need for other metrics if â€˜accuracyâ€™ is already present?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# he model had a very high Accuracy but performed poorly in terms of Precision and Recall.\n",
    "# So, necessarily Accuracy is not the metric to use for evaluating the model in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.\tWhat are Recall and Precision? How do they differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is a measure of: from the total number of positive results \n",
    "# how many positives were correctly predicted by the model.\n",
    "# Recall=  ğ‘‡ğ‘ƒ(ğ‘‡ğ‘ƒ+ğ¹ğ‘)\n",
    "\n",
    "\n",
    "# Precision is a measure of amongst all the positive predictions, how many of them were actually positive. Mathematically,\n",
    "\n",
    "# Precision= ğ‘‡ğ‘ƒ(ğ‘‡ğ‘ƒ+ğ¹ğ‘ƒ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.\tHow does the tradeoff between recall and precision work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with an increase in the Recall, there is a drop in Precision of the model.\n",
    "# in some sceneario we put recall on top most priority and sometime precision\n",
    "# so their are trade off in between them which will maximise both on same time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.\tExplain the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a metric that considers both Precision and Recall for evaluating a model. One such metric is the F1 score.\n",
    "\n",
    "# F1 score is defined as the harmonic mean of Precision and Recall.\n",
    "#  F1 score=  2âˆ—((ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›âˆ—ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™)(ğ‘ƒğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘›+ğ‘…ğ‘’ğ‘ğ‘ğ‘™ğ‘™))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14.\tWhat is specificity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it specific is the model while predicting the True Negatives\n",
    "\n",
    "# Specificity= ğ‘‡ğ‘(ğ‘‡ğ‘+ğ¹ğ‘ƒ) \n",
    "\n",
    "# False Positive rate can be defined as: (1- specificity) Or,  ğ¹ğ‘ƒ(ğ‘‡ğ‘+ğ¹ğ‘ƒ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.\tExplain the significance of ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#while working with real-time data, it has been observed that we seldom get a perfect 0 or 1 value.\n",
    "# Instead of that, we get different decimal values lying between 0 and 1.\n",
    "# Now the question is if we are not getting binary probability values \n",
    "# There comes the concept of Threshold. A threshold is set, any probability value below the threshold is a negative outcome, \n",
    "# and anything more than the threshold is a favourable or the positive outcome. \n",
    "# For Example, if the threshold is 0.5, any probability value below 0.5 means a negative or an unfavourable outcome and \n",
    "# any value above 0.5 indicates a positive or favourable outcome\n",
    "# The horizontal lines represent the various values of thresholds ranging from 0 to 1.\n",
    "#Letâ€™s suppose our classification problem was to identify the obese people from the given data.\n",
    "# The green markers represent obese people and the red markers represent the non-obese people.\n",
    "# Our confusion matrix will depend on the value of the threshold chosen by us.\n",
    "# For Example, if 0.25 is the threshold then\n",
    "#  TP(actually obese)=3\n",
    "#  TN(Not obese)=2\n",
    "#  FP(Not obese but predicted obese)=2(the two red squares above the 0.25 line)\n",
    "#  FN(Obese but predicted as not obese )=1(Green circle below 0.25line  )\n",
    "#   roc is calculated  by senstitvity verse false postive rate '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.\tWhat is AUC, and when is it used?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  we used different classification algorithms, and different ROCs for the corresponding algorithms have been plotted.\n",
    "\n",
    "# Algorithm is choosed by the area under the curve  of each roc curve. \n",
    "# It helps us to choose the best model amongst the models for which we have plotted the ROC curves\n",
    "# The best model is the one which encompasses the maximum area under it.\n",
    "# In the adjacent diagram, amongst the two curves, the model that resulted in the red one should be chosen as it clearly covers more area than the blue one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.\tExplain the steps for Heroku deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After installing the Heroku CLI, Open a command prompt window and navigate to your project folder.\n",
    "#Type the command heroku login to login to your heroku account.\n",
    "#After logging in to Heroku, enter the command heroku create to create a heroku app. It will give you the URL of your Heroku app after successful creation. Or alternatively, you can go to the heroku website and create an app directly.\n",
    "#Before deploying the code to the Heroku cloud, we need to commit the changes to the git repository.\n",
    "#Type the command git init to initialize a local git repository.\n",
    "#Enter the command git status to see the uncommitted changes.\n",
    "#Enter the command git add . to add the uncommitted changes to the local repository.\n",
    "#Enter the command git commit -am \"make it better\" to commit the changes to the local repository.\n",
    "#Enter the command git push heroku master to push the code to the heroku cloud.\n",
    "#After deployment, heroku gives you the URL to hit the web API.\n",
    "#Once your application is deployed successfully, enter the command heroku logs --tail to see the logs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
